---
---

```{r message=FALSE, warning=FALSE}

#library
library(readxl)
library(readr)
library(ggplot2)
library(dplyr)
library(pROC)
library(caret)
library(nnet)
library(glmnet)
library(knitr)
library(rpart)
library(kableExtra)

data <- read_csv("~/NEU Grad docs/ALY6015/Capstone Project/Violence_Reduction_-_Shotspotter_Alerts.csv")

```

```{r}

# Removing rows with missing values
cleaned_data <- na.omit(data)

```

```{r}

# Transform INCIDENT_TYPE_DESCRIPTION to a numerical column, Incident_Type_Code
cleaned_data <- cleaned_data %>%
  mutate(Incident_Type_Code = case_when(
    INCIDENT_TYPE_DESCRIPTION == "SINGLE GUNSHOT" ~ 0,
    INCIDENT_TYPE_DESCRIPTION == "MULTIPLE GUNSHOTS" ~ 1,
    INCIDENT_TYPE_DESCRIPTION %in% c("GUNSHOT OR FIRECRACKER") ~ 1,
  ))

# Assuming the DATE column is in a character format
cleaned_data$DATE <- as.Date(cleaned_data$DATE, format = "%Y-%m-%d")

cleaned_data$ZIP_CODE <- as.numeric(cleaned_data$ZIP_CODE)

head(cleaned_data)

```

<B>
<FONT SIZE = 2, color = "black">
DATA PARTITION
</B><BR>

```{r warning=FALSE}
set.seed(20353)
#partitioning dataset into train and test
# Create separate partitions for columns with different data types
train_indices <- createDataPartition(cleaned_data$Incident_Type_Code, p = 0.70, list = FALSE, times = 1)
train_viol_split <- cleaned_data[train_indices, ]
test_viol_split = cleaned_data[-train_indices,]

```

<B>
<FONT SIZE = 2, color = "black">
GLM - LOGISTIC REGRESSION
</B><BR>

```{r warning=FALSE}
# Fit the GLM model
glm_model <- glm(Incident_Type_Code ~ ZIP_CODE + MONTH + DAY_OF_WEEK + ROUNDS + LATITUDE + LONGITUDE, data = train_viol_split, family = binomial)

# Summary of the model
summary(glm_model)

# Obtain predictions on the test set
predicted_probabilities_test <- predict(glm_model, newdata = test_viol_split, type = "response")

# Convert predicted probabilities to predicted classes (0 or 1)
predicted_classes_test <- ifelse(predicted_probabilities_test > 0.5, 1, 0)

# Create the confusion matrix for test set
conf_matrix_test <- table(Actual = test_viol_split$Incident_Type_Code, Predicted = predicted_classes_test)
conf_matrix_test

# Calculate ROC curve and AUC for test set
roc_curve_test <- roc(test_viol_split$Incident_Type_Code, predicted_probabilities_test)
auc_test <- auc(roc_curve_test)

# Plot ROC curve for training set
plot(roc_curve_test, main = "ROC Curve - Test Set", col = "blue")
legend("bottomright", legend = paste("AUC =", round(auc_test, 3)), col = "blue", lty = 1, cex = 0.8)

```
<B>
<BR>
<FONT SIZE = 2, color = "black">
LINEAR REGRESSION
</B><BR>


```{r}

# Fit the linear regression model
linear_model <- lm(ROUNDS ~ ZIP_CODE + MONTH + DAY_OF_WEEK + ROUNDS + LATITUDE + LONGITUDE, data = train_viol_split)

# Summary of the model
summary(linear_model)

# Make predictions on the test set
linear_predictions <- predict(linear_model, newdata = test_viol_split, type = "response")

# Convert predicted probabilities to binary predictions based on a threshold (e.g., 0.5)
lm_predictions <- ifelse(linear_predictions >= 0.5, 1, 0)

# Compute Mean Squared Error (MSE)
mse <- mean((linear_predictions - test_viol_split$Incident_Type_Code)^2)

# Compute Root Mean Squared Error (RMSE)
rmse <- sqrt(mse)

# Compute Mean Absolute Error (MAE)
mae <- mean(abs(linear_predictions - test_viol_split$Incident_Type_Code))

# Compute R-squared (Coefficient of Determination)
rss <- sum((linear_predictions - mean(test_viol_split$Incident_Type_Code))^2)
tss <- sum((test_viol_split$Incident_Type_Code - mean(test_viol_split$Incident_Type_Code))^2)
rsquared <- 1 - (rss / tss)

# Print evaluation metrics
cat("Mean Squared Error (MSE):", mse, "\n")
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
cat("Mean Absolute Error (MAE):", mae, "\n")
cat("R-squared:", rsquared, "\n")

# Create a table to compare model results
comparison_table <- data.frame(
  Metric = c("Residual Standard Error (RSE)", "Mean Squared Error (MSE)", "Root Mean Squared Error (RMSE)",
             "Mean Absolute Error (MAE)", "Multiple R-squared", "Adjusted R-squared"),
  Trained_Data = c(0.4117, NA, NA, NA, 0.2291, 0.2291),
  Test_Data = c(NA, 0.1695297, 0.4117399, 0.3795446, NA, NA)
)

# Print the comparison table with formatting
kable(comparison_table, align = c("c", "c", "c"), caption = "Comparison of Model Results between Trained Data and Test Data") %>%
  kable_styling(bootstrap_options = "basic")

# Extract predictor variables from both trained and test datasets
predictor_trained <- train_viol_split[, c("ZIP_CODE", "MONTH", "DAY_OF_WEEK", "ROUNDS", "LATITUDE", "LONGITUDE")]
predictor_test <- test_viol_split[, c("ZIP_CODE", "MONTH", "DAY_OF_WEEK", "ROUNDS", "LATITUDE", "LONGITUDE")]

```

<B>
<FONT SIZE = 2, color = "black">
DECISION TREE - MODEL
</B><BR>

```{r message=FALSE,warning=FALSE}

# Fitting a Decision Tree model
decision_tree_model <- rpart(Incident_Type_Code ~ ZIP_CODE + MONTH + DAY_OF_WEEK + ROUNDS + LATITUDE + LONGITUDE, data = train_viol_split, method="class")

# Viewing the decision tree
print(decision_tree_model)

# Make predictions on the test set
predictions <- predict(decision_tree_model, newdata = test_viol_split, type = "prob")

# Extract probabilities for the positive class
predicted_probabilities <- predictions[, "1"]

# Calculate ROC curve
roc_curve1 <- roc(ifelse(test_viol_split$Incident_Type_Code == "1", 1, 0), predicted_probabilities)

# Calculate AUC
auc_value1 <- auc(roc_curve1)

# Plot ROC curve for training set
plot(roc_curve1, main = "ROC Curve - Test Set", col = "blue")
legend("bottomright", legend = paste("AUC =", round(auc_value1, 3)), col = "blue", lty = 1, cex = 0.8)

# Convert predicted probabilities to binary predictions based on a threshold (e.g., 0.5)
DT_predictions <- ifelse(predicted_probabilities >= 0.5, 1, 0)

# Create the confusion matrix
confusion_matrix <- table(DT_predictions, test_viol_split$Incident_Type_Code)

# Print the confusion matrix
print(confusion_matrix)

```

